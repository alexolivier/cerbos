include::ROOT:partial$attributes.adoc[]

[#recipe-ai-rag-authorization]

= Implementing authorization in RAG-based AI systems

As companies implement AI applications, a Retrieval Augmented Generation (RAG) architecture is often used to give an LLM context from internal data. The challenge that consequently arises is how to provide the LLM with sufficient context without violating privacy and authorization policies. Companies need to ensure that AI agents canâ€™t inappropriately access sensitive data or expose it to unauthorized users. 


== How the Cerbos query plan works with RAG

video::4VBHpziqw3o[youtube,width=640,height=360]

RAG architecture can leverage large data sets of internal knowledge: documents, meeting notes, and resources to provide business-specific context to the LLM. This business data first has to be extracted from the system of record (ERP, CRM, HRIS, etc), go through an embedding process, and then be loaded into a vector store - which is a specialized database that can find related documents based on their contents. Vector stores also support metadata such as what the source system was, which department it belongs to and which region it's associated with. This can all be leveraged for authorization.

With the business data stored along with its associated metadata, a typical workflow would be to put a chatbot-style interface in front which, using Cerbos, can apply authorization logic to the retrieval:

A user interacts with the LLM by asking a simple question which is vectorized via an embedding model.

1. The filters applicable to the user are generated by the Cerbos Policy Decision Point (PDP).
2. Then the embedded data store is queried for applicable documents based on the input, with metadata filters based on authorization policies used to re strict which documents the LLM can retrieve.
3. The retrieved documents are injected into the prompt.
4. The LLM processes the prompt to generate the answer.

== Leveraging Cerbos Query Plan for authorization

Cerbos can be used to enforce authorization policies on the data retrieval step in the RAG architecture. The Cerbos Query Plan can be used to generate filters based on the user's identity and the metadata associated with the data. This ensures that the LLM only retrieves data that the user is authorized to access.

As an example, consider a scenario where a user asks the LLM for information about a specific project. This project is associated with a department and a region and only those users in the same department or region should be able to access it. The Cerbos policy for this could be defined as follows:

[source, yaml]
----
apiVersion: api.cerbos.dev/v1
resourcePolicy:
  version: "default"
  resource: "project"

  rules:
    - actions: ["read"]
      effect: EFFECT_ALLOW
      condition:
        all:
          of:
            - expr: R.attr.department == P.attr.department
            - expr: R.attr.region == P.attr.region

    # ... other rules
----

When a user is interacting with the chatbot experience, their identity is passed to the Cerbos PDP in a xref:api:index.adoc#plan-resources[PlanResources] request with their region and department as attributes and with `project` being the resource type and the action set to `read`.

[source, json]
----
{
  "principal": {
    "id": "alice",
    "roles": [
      "USER",
      "MANAGER"
    ],
    "attr": {
      "department": "FINANCE",
      "region": "EMEA"
    }
  },
  "resource": {
    "kind": "project",
  },
  "action": "read",
}
----

The Query Plan generated by Cerbos would then include the following conditions - note that the actual response is completely dynamic and depends on the user's identity and the policy defined in Cerbos:

[source, json]
----
{
  "action": "read",
  "resourceKind": "project",
  "filter": {
    "kind": "KIND_CONDITIONAL",
    "condition": {
      "expression": {
        "operator": "and",
        "operands": [
          {
            "expression": {
              "operator": "eq",
              "operands": [
                {
                  "variable": "request.resource.attr.department"
                },
                {
                  "value": "FINANCE"
                }
              ]
            }
          },
          {
            "expression": {
              "operator": "eq",
              "operands": [
                {
                  "variable": "request.resource.attr.region"
                },
                {
                  "value": "EMEA"
                }
              ]
            }
          }
        ]
      }
    }
  }
}
----

This set of conditions then can be converted into a metadata filter that can be applied to the vector store query to ensure that only the data that the user is authorized to access is retrieved. Each vector store has it's own syntax for defining filters, but in the case of https://www.trychroma.com/[Chroma], this would look like:

[source, json]
----
{
  "$and": [
    {"department": "FINANCE"},
    {"region": "EMEA"}
  ]
}
----

With this filter in place, any documents retired from the vector store would be limited to those that match the user's department and region, ensuring that the LLM only receives data that the user is authorized to access before passing it into the prompt and onto the LLM.

== Conclusion

Implementing authorization in RAG-based AI systems is crucial to ensure that sensitive data is not exposed to unauthorized users. Cerbos can be used to enforce authorization policies on the data retrieval step in the RAG architecture, ensuring that the LLM only retrieves data that the user is authorized to access. By leveraging Cerbos Query Plan, companies can provide the LLM with sufficient context without violating privacy and authorization policies.
